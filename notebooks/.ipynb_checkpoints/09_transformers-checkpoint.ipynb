{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liable-focus",
   "metadata": {},
   "source": [
    "# Week 9: Sequence Models and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-encyclopedia",
   "metadata": {},
   "source": [
    "Additional references: \n",
    "- [Character Level Language Model (GPU required)](https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/06_deep_nlp/Character_Level_Language_Model_rendered.ipynb)\n",
    "- [Transformers (BERT fine-tuning): Joint Intent Classification and Slot Filling](https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/06_deep_nlp/Transformers_Joint_Intent_Classification_Slot_Filling_rendered.ipynb)\n",
    "- [Generating Language with huggingface](https://huggingface.co/blog/how-to-generate)\n",
    "- [huggingface examples](https://huggingface.co/transformers/quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intermediate-operations",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:28:40.562418Z",
     "start_time": "2022-05-05T16:28:40.194542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 819\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   case_name       768 non-null    object        \n",
      " 1   opinion_type    768 non-null    object        \n",
      " 2   date_standard   768 non-null    datetime64[ns]\n",
      " 3   authorship      768 non-null    object        \n",
      " 4   x_republican    768 non-null    float64       \n",
      " 5   maj_judges      768 non-null    object        \n",
      " 6   dissent_judges  768 non-null    object        \n",
      " 7   topic_id        768 non-null    float64       \n",
      " 8   cite_count      768 non-null    float64       \n",
      " 9   opinion_text    768 non-null    object        \n",
      " 10  year            768 non-null    int64         \n",
      " 11  log_cite_count  768 non-null    float64       \n",
      " 12  author_id       768 non-null    int8          \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), int8(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('sc_cases_cleaned.pkl', compression='gzip')\n",
    "df = df.assign(author_id=(df['authorship']).astype('category').cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-saskatchewan",
   "metadata": {},
   "source": [
    "# Huggingface Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "successful-elite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:28:43.360106Z",
     "start_time": "2022-05-05T16:28:42.904969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# gpu or cpu?\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-grant",
   "metadata": {},
   "source": [
    "Load the model from a pretrained checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-stone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:29:04.222014Z",
     "start_time": "2022-05-05T16:28:45.142458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ae74f8af064d0e8ba4c954e7456299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-uncased' # huggingface model_ID or path to folder \n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premium-monitor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:29:46.864883Z",
     "start_time": "2022-05-05T16:29:42.989169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4669 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  3425, 18353,  ...,  3641,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "inputs = tokenizer(df.iloc[0]['opinion_text'], return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "particular-desperate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:45:38.818606Z",
     "start_time": "2022-05-05T16:45:37.127328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  3425, 18353,  ...,  6525,  3089,   102],\n",
      "        [  101,  3425,  8799,  ...,  4781,  2580,   102],\n",
      "        [  101,  3425,  1051,  ..., 13931,  9964,   102],\n",
      "        ...,\n",
      "        [  101,  3425,  8040,  ...,  2005,  1996,   102],\n",
      "        [  101,  3425,  2726,  ...,  2015,  2006,   102],\n",
      "        [  101,  3425,  1051,  ..., 25394, 11461,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])} tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(df['opinion_text'].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "labels = torch.tensor(df['x_republican'].tolist()).long() \n",
    "print(inputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-coaching",
   "metadata": {},
   "source": [
    "More infos about huggingface tokenizers can be found [here](https://huggingface.co/transformers/main_classes/tokenizer.html).\n",
    "\n",
    "Now we have a set of text inputs and authors indicators as labels and we can train a transformers model using a cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outstanding-tolerance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:45:40.928552Z",
     "start_time": "2022-05-05T16:45:38.819643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [174 594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "unique_labels, counts = np.unique(df[\"x_republican\"], return_counts=True)\n",
    "print (unique_labels, counts)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(unique_labels))\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.distilbert.parameters(), 'lr': 1e-5},  \n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "medium-bangkok",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:45:41.393502Z",
     "start_time": "2022-05-05T16:45:40.929799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608,) (152,) (608,) (152,)\n",
      "(76, 8) (19, 8) (76, 8) (19, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['opinion_text'].tolist(), df['x_republican'].tolist(), test_size=.2)\n",
    "\n",
    "# generate batches\n",
    "X_train, X_test, y_train, y_test = np.array(X_train[:608]), np.array(X_test[:152]), np.array(y_train[:608]), np.array(y_test[:152])\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.reshape(-1, 8), X_test.reshape(-1, 8), y_train.reshape(-1, 8), y_test.reshape(-1, 8)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "X_train, X_test = X_train.tolist(), X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "satisfactory-shakespeare",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:47:09.918297Z",
     "start_time": "2022-05-05T16:45:42.809048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 76/76 [01:27<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for text, labels in tqdm(zip(X_train, y_train), total=len(X_train)):\n",
    "        # prepare model input through our tokenizer\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "        # place everything on the right device\n",
    "        model_inputs = {k:v.to(device) for k,v in model_inputs.items()}\n",
    "        # labels have to be torch long tensors\n",
    "        labels = torch.tensor(labels).long()\n",
    "        # now, we can perform the forward pass\n",
    "        output = model(**model_inputs, labels=labels)\n",
    "        loss, logits = output[:2]\n",
    "        # and the backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scenic-noise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:47:46.266853Z",
     "start_time": "2022-05-05T16:47:32.428236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:13<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.993421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98        30\n",
      "         1.0       0.99      1.00      1.00       122\n",
      "\n",
      "    accuracy                           0.99       152\n",
      "   macro avg       1.00      0.98      0.99       152\n",
      "weighted avg       0.99      0.99      0.99       152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, targets = [], []\n",
    "model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text, labels in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        model_inputs = {k:v.to(device) for k,v in model_inputs.items()}\n",
    "\n",
    "        output = model(**model_inputs)\n",
    "        logits = output[0]\n",
    "        # prediction is the argmax of the logits\n",
    "        predictions.extend(logits.argmax(dim=1).tolist())\n",
    "        targets.extend(labels)\n",
    "        \n",
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(targets, predictions)\n",
    "print (\"accuracy\", accuracy)\n",
    "classification_report = metrics.classification_report(targets, predictions)\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-loading",
   "metadata": {},
   "source": [
    "So far, we considered the pytorch version for transformers. It also works with keras, a more in-depth tutorial can be found [here](https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "killing-muslim",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:51:32.596448Z",
     "start_time": "2022-05-05T16:51:01.740495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae053c6f12a45d5ae89f597d0affef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:51:29.212525: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-05 18:51:29.212755: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-05-05 18:51:29.232833: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "# note that we use TFDistilBert... instead of DistilBert...\n",
    "\n",
    "transformer_model = TFDistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# define model input layer\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(256,), name='masked_token', dtype='int32')\n",
    "X = transformer_model(input_ids, input_masks_ids)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressive-lightning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:51:32.605055Z",
     "start_time": "2022-05-05T16:51:32.597485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_token (InputLayer)       [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)      [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66955010   ['input_token[0][0]',            \n",
      " assification (TFDistilBertForS  rOutput(loss=None,               'masked_token[0][0]']           \n",
      " equenceClassification)         logits=(None, 2),                                                 \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legendary-homeless",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:54:06.621809Z",
     "start_time": "2022-05-05T16:54:06.593204Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', # cost function\n",
    "              optimizer='adam', # use adam as the optimizer\n",
    "              metrics=['accuracy']) # compute accuracy, for scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "temporal-addiction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:54:15.329792Z",
     "start_time": "2022-05-05T16:54:07.325002Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize X_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['opinion_text'].tolist(), df['x_republican'].tolist(), test_size=.2)\n",
    "X_train_tf = [tokenizer(x, return_tensors=\"tf\", padding=True, truncation=True, max_length=256) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indirect-volleyball",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:54:15.427831Z",
     "start_time": "2022-05-05T16:54:15.330762Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids, input_masks = [x[\"input_ids\"][0].numpy() for x in X_train_tf], [x[\"attention_mask\"][0].numpy() for x in X_train_tf]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({'input_token': input_ids, 'masked_token': input_masks}, y_train)).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "centered-clinton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:54:48.434829Z",
     "start_time": "2022-05-05T16:54:15.428719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:54:18.169262: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-05 18:54:18.169761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 33s 335ms/step - loss: 0.7658 - accuracy: 0.7329\n"
     ]
    }
   ],
   "source": [
    "model_info = model.fit(dataset,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328d6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:51:19.545240Z",
     "start_time": "2022-03-28T13:51:19.525343Z"
    }
   },
   "source": [
    "# LSTM in keras\n",
    "\n",
    "Because we have an embedding lookup now, we can train an LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4ba0cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:52:53.421160Z",
     "start_time": "2022-05-05T17:52:51.456301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4440, 7346, 6759, 312, 4915, 5728, 312, 9977, 8828, 8087, 1233, 8828, 9674, 7025, 4764, 3607, 8577, 8865, 8429, 3081, 8491, 1435, 9544, 4275, 5993, 8222, 9393, 8828, 6679, 7745, 5100, 9575, 6728, 4731, 8176, 8649, 312, 8455, 3022, 6706, 312, 6873, 5728, 1736, 1194, 2658, 9544, 4275, 1054, 5409]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "length_vocab = 10000\n",
    "Y = df['x_republican']\n",
    "X_one_hot = [one_hot(opinion, n=length_vocab) for opinion in df[\"opinion_text\"]]\n",
    "print (X_one_hot[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3a432a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:54:01.942006Z",
     "start_time": "2022-05-05T17:54:01.872745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 2000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, we pad (or truncate) such that all the inputs have same length\n",
    "\n",
    "max_seq_length = 2000\n",
    "X_one_hot_padded = pad_sequences(X_one_hot, padding='post', maxlen=max_seq_length, truncating='post')\n",
    "X_one_hot_padded.shape # (768, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac126a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:56:43.915607Z",
     "start_time": "2022-05-05T17:56:43.764375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding)  (None, 2000, 32)         320000    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329,409\n",
      "Trainable params: 329,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "model = Sequential() # create a sequential model\n",
    "model.add(Embedding(length_vocab, 32, input_length=max_seq_length, name=\"embedding_layer\"))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) # output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be2cde8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:45:42.141618Z",
     "start_time": "2022-05-05T17:45:41.691961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"333pt\" height=\"376pt\" viewBox=\"0.00 0.00 342.00 387.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.972222 0.972222) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-383 338,-383 338,4 -4,4\"/>\n",
       "<!-- 17345583856 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>17345583856</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-332.5 3,-378.5 331,-378.5 331,-332.5 3,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"41.5\" y=\"-351.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"80,-332.5 80,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"80,-355.5 135,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"135,-332.5 135,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"184\" y=\"-351.8\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2000)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"233,-332.5 233,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"282\" y=\"-351.8\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 2000)]</text>\n",
       "</g>\n",
       "<!-- 17345584432 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>17345584432</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-249.5 0,-295.5 334,-295.5 334,-249.5 0,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"40\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"80,-249.5 80,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"80,-272.5 135,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"135,-249.5 135,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2000)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"224,-249.5 224,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"279\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2000, 32)</text>\n",
       "</g>\n",
       "<!-- 17345583856&#45;&gt;17345584432 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>17345583856-&gt;17345584432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167,-332.37C167,-324.15 167,-314.66 167,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.5,-305.61 167,-295.61 163.5,-305.61 170.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 17345583328 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>17345583328</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20,-166.5 20,-212.5 314,-212.5 314,-166.5 20,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"46.5\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73,-166.5 73,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"100.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"73,-189.5 128,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"100.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"128,-166.5 128,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2000, 32)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"238,-166.5 238,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 17345584432&#45;&gt;17345583328 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>17345584432-&gt;17345583328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167,-249.37C167,-241.15 167,-231.66 167,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.5,-222.61 167,-212.61 163.5,-222.61 170.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 17012869680 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>17012869680</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"38.5,-83.5 38.5,-129.5 295.5,-129.5 295.5,-83.5 38.5,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88.5,-83.5 88.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"88.5,-106.5 143.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"143.5,-83.5 143.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 32)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"219.5,-83.5 219.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 17345583328&#45;&gt;17012869680 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>17345583328-&gt;17012869680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167,-166.37C167,-158.15 167,-148.66 167,-139.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.5,-139.61 167,-129.61 163.5,-139.61 170.5,-139.61\"/>\n",
       "</g>\n",
       "<!-- 14067350208 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>14067350208</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42,-0.5 42,-46.5 292,-46.5 292,-0.5 42,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"67\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"92,-0.5 92,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"92,-23.5 147,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"147,-0.5 147,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"185\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 32)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"223,-0.5 223,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 17012869680&#45;&gt;14067350208 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>17012869680-&gt;14067350208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167,-83.37C167,-75.15 167,-65.66 167,-56.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.5,-56.61 167,-46.61 163.5,-56.61 170.5,-56.61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "dot = model_to_dot(model,\n",
    "                   show_shapes=True,\n",
    "                   show_layer_names=False,\n",
    "                   dpi=70)\n",
    "SVG(dot.create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f38db83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T17:56:35.535049Z",
     "start_time": "2022-05-05T17:54:35.976224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 19:54:36.658818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-05 19:54:36.888325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-05 19:54:47.805706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 [===========================>..] - ETA: 0s - loss: 0.6579 - accuracy: 0.7747"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# cost function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# use adam as the optimizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# compute accuracy, for scoring\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_one_hot_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/University/NLP-LSS/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', # cost function\n",
    "              optimizer='adam', # use adam as the optimizer\n",
    "              metrics=['accuracy']) # compute accuracy, for scoring\n",
    "\n",
    "model_info = model.fit(X_one_hot_padded, Y, \n",
    "                      epochs=3,\n",
    "                      validation_split=.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c1164",
   "metadata": {},
   "source": [
    "**Text Vectorization Layer** <br>\n",
    "more details [here](https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14dd646f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T18:00:50.904497Z",
     "start_time": "2022-05-05T18:00:50.224391Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 20:00:50.304290: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(df[\"opinion_text\"])\n",
    "max_features = 10000  # Maximum vocab size.\n",
    "max_len = 2000  # Sequence length to pad the outputs to.\n",
    "\n",
    "# Create the layer.  \n",
    "vectorize_layer = TextVectorization(\n",
    " max_tokens=max_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_len)\n",
    "# Now that the vocab layer has been created, call `adapt` on the text-only  \n",
    "# dataset to create the vocabulary. You don't have to batch, but for large  \n",
    "# datasets this means we're not keeping spare copies of the dataset.\n",
    "\n",
    "\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d311667d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T18:03:46.978027Z",
     "start_time": "2022-05-05T18:00:52.773718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 2000)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 2000, 64)         640000    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,249\n",
      "Trainable params: 677,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 20:00:54.130902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-05 20:00:54.412815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-05 20:01:05.444359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.7508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 20:02:56.335235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-05 20:02:56.425617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 145s 5s/step - loss: 0.6277 - accuracy: 0.7508 - val_loss: 0.5600 - val_accuracy: 0.7662\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 14s 701ms/step - loss: 0.5263 - accuracy: 0.7752 - val_loss: 0.5468 - val_accuracy: 0.7662\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 14s 706ms/step - loss: 0.4732 - accuracy: 0.7752 - val_loss: 0.5661 - val_accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(max_features, 64, name=\"embedding_layer\"))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) # output layer\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # cost function\n",
    "              optimizer='adam', # use adam as the optimizer\n",
    "              metrics=['accuracy']) # compute accuracy, for scoring\n",
    "\n",
    "model_info = model.fit(df[\"opinion_text\"], Y, \n",
    "                      epochs=3,\n",
    "                      validation_split=.2, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb059bc9",
   "metadata": {},
   "source": [
    "**Deep learning tips, tricks and advanced features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd958785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:24.881012Z",
     "start_time": "2022-03-28T13:52:24.573352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up a basic model again for advanced features.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "# set custom activation, specify input dim\n",
    "model.add(Dense(64, input_dim=1000, activation='gelu')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a630090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:31.224246Z",
     "start_time": "2022-03-28T13:52:31.191604Z"
    }
   },
   "outputs": [],
   "source": [
    "# initializers\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Dense(64, kernel_initializer='he_uniform'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2506ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:35.672196Z",
     "start_time": "2022-03-28T13:52:35.647331Z"
    }
   },
   "outputs": [],
   "source": [
    "# other activation functions (https://keras.io/activations/)\n",
    "model.add(Dense(64, activation=\"elu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00715651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:39.947691Z",
     "start_time": "2022-03-28T13:52:39.936613Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch normalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "model.add(Dense(64, use_bias=False)) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e4f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:45.714411Z",
     "start_time": "2022-03-28T13:52:45.679221Z"
    }
   },
   "outputs": [],
   "source": [
    "# regularization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "model.add(Dense(64, \n",
    "                kernel_regularizer=l2(0.01),\n",
    "                activity_regularizer=l1(0.01)))\n",
    "model.add(Dense(64, \n",
    "                kernel_regularizer=l1_l2(l1=0.01,l2=.01),\n",
    "                activity_regularizer=l1_l2(l1=0.01,l2=.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24206ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:50.267897Z",
     "start_time": "2022-03-28T13:52:50.254319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "from keras.layers import Dropout\n",
    "# np.random.rand(1000)\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb5a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:54.944225Z",
     "start_time": "2022-03-28T13:52:54.839028Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f17b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:52:59.699546Z",
     "start_time": "2022-03-28T13:52:59.676350Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56b9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:53:04.778410Z",
     "start_time": "2022-03-28T13:53:04.746811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# different loss functions\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:53:09.279180Z",
     "start_time": "2022-03-28T13:53:09.256501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', \n",
    "                          min_delta=0.0001, \n",
    "                          patience=5, \n",
    "                          mode='auto')\n",
    "\n",
    "\n",
    "model.fit(X.todense(), Y, batch_size=128, \n",
    "           epochs=100, \n",
    "           callbacks=[earlystop], \n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3a8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T13:53:14.483691Z",
     "start_time": "2022-03-28T13:53:14.415420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Batch Training with Large Data\n",
    "from numpy import memmap\n",
    "X_mm = memmap('X.pkl',shape=(768, 1000))\n",
    "\n",
    "model.fit(X_mm, Y, batch_size=128, \n",
    "           epochs=3, \n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cdefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with KerasClassifier\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# instantiate KerasClassifier with build function\n",
    "def create_model(hidden_layers=1):  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=1000, \n",
    "                    activation='relu')) \n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                optimizer='adam', \n",
    "                metrics= ['accuracy'])\n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(create_model)\n",
    "\n",
    "# set of grid search CV to select number of hidden layers\n",
    "params = {'hidden_layers' : [0,1,2,3]}\n",
    "grid = GridSearchCV(clf, param_grid=params)\n",
    "grid.fit(X.todense(),Y)\n",
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
