{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-velvet",
   "metadata": {},
   "source": [
    "# Week 11: Transformers Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-louisiana",
   "metadata": {},
   "source": [
    "Additional references: \n",
    "- [Question Answering with huggingface](https://huggingface.co/transformers/usage.html)\n",
    "- [Textual Entailment](https://nlp.stanford.edu/pubs/snli_paper.pdf)\n",
    "- [SQuAD question answering](https://arxiv.org/abs/1606.05250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earlier-priority",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:52:59.713434Z",
     "start_time": "2022-05-19T14:52:59.366291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 819\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   case_name       768 non-null    object        \n",
      " 1   opinion_type    768 non-null    object        \n",
      " 2   date_standard   768 non-null    datetime64[ns]\n",
      " 3   authorship      768 non-null    object        \n",
      " 4   x_republican    768 non-null    float64       \n",
      " 5   maj_judges      768 non-null    object        \n",
      " 6   dissent_judges  768 non-null    object        \n",
      " 7   topic_id        768 non-null    float64       \n",
      " 8   cite_count      768 non-null    float64       \n",
      " 9   opinion_text    768 non-null    object        \n",
      " 10  year            768 non-null    int64         \n",
      " 11  log_cite_count  768 non-null    float64       \n",
      " 12  author_id       768 non-null    int8          \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), int8(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('sc_cases_cleaned.pkl', compression='gzip')\n",
    "df = df.assign(author_id=(df['authorship']).astype('category').cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58d0ce",
   "metadata": {},
   "source": [
    "# Coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "awful-pepper",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:56:28.669492Z",
     "start_time": "2022-05-19T14:54:28.016159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f50359bf5e4c4f80cd8029717eb44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading:   0%|          | 0.00/1.25G [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06542d7319ad4c1a9949c3ccacc5dc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928a69309e3e48b59d316f8225902ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d9da2601964b8c97966bc39ef1150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/634M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz\")\n",
    "predictions = predictor.predict(\n",
    "    document=\"Paul Allen was born on January 21, 1953, in Seattle, Washington, to Kenneth Sam Allen and Edna Faye Allen. Allen attended Lakeside School, a private school in Seattle, where he befriended Bill Gates, two years younger, with whom he shared an enthusiasm for computers.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "entertaining-square",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T16:02:20.506162Z",
     "start_time": "2022-05-19T16:02:20.493725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Cluster==\n",
      "Paul Allen \n",
      "Allen \n",
      "he \n",
      "he \n",
      "==Cluster==\n",
      "Seattle , Washington \n",
      "Seattle \n"
     ]
    }
   ],
   "source": [
    "for cluster in predictions['clusters']:\n",
    "    print(\"==Cluster==\")\n",
    "    for element in cluster:\n",
    "        entity = \"\"\n",
    "        for el in range(element[0], element[1]+1):\n",
    "            entity += predictions['document'][el] + \" \"\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "characteristic-receptor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:57:01.026574Z",
     "start_time": "2022-05-19T14:57:01.011893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Paul', 'Allen', 'was', 'born', 'on', 'January', '21', ',', '1953', ','],\n",
       " [[[0, 1], [24, 24], [36, 36], [47, 47]], [[11, 13], [33, 33]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = predictions['clusters']\n",
    "document = predictions['document']\n",
    "document[:10], clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stock-sound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:57:01.600214Z",
     "start_time": "2022-05-19T14:57:01.590724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Paul',\n",
       " 1: 'Allen',\n",
       " 2: 'was',\n",
       " 3: 'born',\n",
       " 4: 'on',\n",
       " 5: 'January',\n",
       " 6: '21',\n",
       " 7: ',',\n",
       " 8: '1953',\n",
       " 9: ',',\n",
       " 10: 'in',\n",
       " 11: 'Seattle',\n",
       " 12: ',',\n",
       " 13: 'Washington',\n",
       " 14: ',',\n",
       " 15: 'to',\n",
       " 16: 'Kenneth',\n",
       " 17: 'Sam',\n",
       " 18: 'Allen',\n",
       " 19: 'and',\n",
       " 20: 'Edna',\n",
       " 21: 'Faye',\n",
       " 22: 'Allen',\n",
       " 23: '.',\n",
       " 24: 'Allen',\n",
       " 25: 'attended',\n",
       " 26: 'Lakeside',\n",
       " 27: 'School',\n",
       " 28: ',',\n",
       " 29: 'a',\n",
       " 30: 'private',\n",
       " 31: 'school',\n",
       " 32: 'in',\n",
       " 33: 'Seattle',\n",
       " 34: ',',\n",
       " 35: 'where',\n",
       " 36: 'he',\n",
       " 37: 'befriended',\n",
       " 38: 'Bill',\n",
       " 39: 'Gates',\n",
       " 40: ',',\n",
       " 41: 'two',\n",
       " 42: 'years',\n",
       " 43: 'younger',\n",
       " 44: ',',\n",
       " 45: 'with',\n",
       " 46: 'whom',\n",
       " 47: 'he',\n",
       " 48: 'shared',\n",
       " 49: 'an',\n",
       " 50: 'enthusiasm',\n",
       " 51: 'for',\n",
       " 52: 'computers',\n",
       " 53: '.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "doc = {}\n",
    "for obj in document:    \n",
    "    doc.update({n :  obj}) #creating a dictionary of each word with its respective index\n",
    "    n = n+1\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "natural-mumbai",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:57:03.566846Z",
     "start_time": "2022-05-19T14:57:03.544720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Paul', 'Allen', 'Allen', 'he', 'he'], ['Seattle', ',', 'Washington', 'Seattle']]\n"
     ]
    }
   ],
   "source": [
    "clus_all = []\n",
    "cluster = []\n",
    "clus_one = {}\n",
    "for i in range(0, len(clusters)):    \n",
    "    one_cl = clusters[i]    \n",
    "    for count in range(0, len(one_cl)):           \n",
    "        obj = one_cl[count]        \n",
    "        for num in range((obj[0]), (obj[1]+1)):            \n",
    "            for n in doc:                \n",
    "                if num == n:                 \n",
    "                    cluster.append(doc[n]) \n",
    "    clus_all.append(cluster)       \n",
    "    cluster = []\n",
    "    \n",
    "print(clus_all) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-testament",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forty-understanding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:57:26.371803Z",
     "start_time": "2022-05-19T14:57:05.261820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299dd5b60f1d45e29cbe1dcc30d7a5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8aa39e30de4de9a625b533d8e33550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4076f5b3b1664f17aec52873f65f6c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbd53740ee44b1fb07ba30b2d0e0053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a8166e8af94fedacd5dcb515c4f215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6222440600395203, 'start': 34, 'end': 95, 'answer': 'the task of extracting an answer from a text given a question'}\n",
      "{'score': 0.5115328431129456, 'start': 147, 'end': 160, 'answer': 'SQuAD dataset'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the `run_squad.py`.\n",
    "\"\"\"\n",
    "\n",
    "print(nlp(question=\"What is extractive question answering?\", context=context))\n",
    "print(nlp(question=\"What is a good example of a question answering dataset?\", context=context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-taste",
   "metadata": {},
   "source": [
    "# Textual Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b449e",
   "metadata": {},
   "source": [
    "premise: Two women are wandering along the shore drinking iced tea.\n",
    "hypothesis: Two women are sitting on a blanket near some rocks talking about politics.\n",
    "label: (premise -> hypothesis, premise ? hypothesis, premise -x hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vietnamese-singles",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:59:13.083430Z",
     "start_time": "2022-05-19T14:57:31.393713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc6b9255a3d4ca1a3852072c7ba9d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading:   0%|          | 0.00/665M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b58a719b654104bca42ca4acd042c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading:   0%|          | 0.00/336 [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8707a2a5e86e4255ad136dc9ec40a624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading:   0%|          | 0.00/357M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using AllenNLP\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/decomposable-attention-elmo-2020.04.09.tar.gz\")\n",
    "prediction = predictor.predict(\n",
    "    premise=\"Two women are wandering along the shore drinking iced tea.\",\n",
    "    hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "latin-curtis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:59:16.131356Z",
     "start_time": "2022-05-19T14:59:16.117057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00033908855402842164, 0.9735872745513916, 0.02607365883886814]\n",
      "Contradiction\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "id2label = {0:\"Entailment\", 1:\"Contradiction\", 2:\"Neutral\"} # https://demo.allennlp.org/textual-entailment/elmo-snli\n",
    "print (prediction[\"label_probs\"])\n",
    "print (id2label[np.argmax(prediction[\"label_probs\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eligible-electron",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:59:24.565933Z",
     "start_time": "2022-05-19T14:59:17.551656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# using Transformers\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "model_name = \"roberta-large-mnli\" # mnli refers to the following dataset on which roberta was trained: https://cims.nyu.edu/~sbowman/multinli/\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "latin-genesis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:59:40.798148Z",
     "start_time": "2022-05-19T14:59:40.786456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Two women are wandering along the shore drinking iced tea.</s></s>Two women are sitting on a blanket near some rocks talking about politics.</s>\n"
     ]
    }
   ],
   "source": [
    "premise=\"Two women are wandering along the shore drinking iced tea.\"\n",
    "hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    "\n",
    "model_input = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "print (tokenizer.decode(model_input[\"input_ids\"][0]))\n",
    "# note how we obtain a single sequence with <s>premise</s></s>hypothesis</s>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "focused-filename",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T14:59:42.612613Z",
     "start_time": "2022-05-19T14:59:42.474419Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "import torch\n",
    "\n",
    "output = model(**model_input)\n",
    "softmax = Softmax()\n",
    "probs = softmax(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "protecting-fireplace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T15:00:23.831558Z",
     "start_time": "2022-05-19T15:00:23.819065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8877, 0.1107, 0.0016]], grad_fn=<SoftmaxBackward0>)\n",
      "Contradiction\n"
     ]
    }
   ],
   "source": [
    "print (probs)\n",
    "\n",
    "id2label = {0:\"Contradiction\", 1:\"Neutral\", 2:\"Entailment\"} # these are label2id from MNLI\n",
    "\n",
    "argmax = torch.argmax(output.logits[0].detach()).item()\n",
    "print (id2label[argmax])\n",
    "\n",
    "#print (id2label[torch.argmax(output.logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "metallic-navigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T15:00:51.812594Z",
     "start_time": "2022-05-19T15:00:51.793187Z"
    }
   },
   "outputs": [],
   "source": [
    "# do it for a whole batch\n",
    "\n",
    "premises = [\"If you help the needy, God will reward you.\", \"An interplanetary spacecraft is in orbit around a gas giant's icy moon.\", \"A large, gray elephant walked beside a herd of zebras.\", \"A handmade djembe was on display at the Smithsonian.\"]\n",
    "hypotheses = [\"Giving money to the poor has good consequences.\", \"The spacecraft has the ability to travel between planets.\", \"The elephant was lost.\", \"Visitors could see the djembe.\"] \n",
    "\n",
    "model_inputs = tokenizer(premises, hypotheses, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "characteristic-glossary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T15:00:53.231326Z",
     "start_time": "2022-05-19T15:00:53.019167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you help the needy, God will reward you. -- Giving money to the poor has good consequences. -- Entailment\n",
      "An interplanetary spacecraft is in orbit around a gas giant's icy moon. -- The spacecraft has the ability to travel between planets. -- Neutral\n",
      "A large, gray elephant walked beside a herd of zebras. -- The elephant was lost. -- Neutral\n",
      "A handmade djembe was on display at the Smithsonian. -- Visitors could see the djembe. -- Entailment\n"
     ]
    }
   ],
   "source": [
    "output = model(**model_inputs)\n",
    "softmax = Softmax()\n",
    "probs = softmax(output.logits)\n",
    "\n",
    "for premise, hypothesis, prediction in zip(premises, hypotheses, probs):\n",
    "    argmax = torch.argmax(prediction).item()\n",
    "    print (premise, \"--\", hypothesis, \"--\", id2label[argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa7e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
