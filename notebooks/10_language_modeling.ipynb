{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba611b5",
   "metadata": {},
   "source": [
    "# Week 10: Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61002077",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc138ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T17:50:21.395507Z",
     "start_time": "2022-05-12T17:50:21.045840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 819\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   case_name       768 non-null    object        \n",
      " 1   opinion_type    768 non-null    object        \n",
      " 2   date_standard   768 non-null    datetime64[ns]\n",
      " 3   authorship      768 non-null    object        \n",
      " 4   x_republican    768 non-null    float64       \n",
      " 5   maj_judges      768 non-null    object        \n",
      " 6   dissent_judges  768 non-null    object        \n",
      " 7   topic_id        768 non-null    float64       \n",
      " 8   cite_count      768 non-null    float64       \n",
      " 9   opinion_text    768 non-null    object        \n",
      " 10  year            768 non-null    int64         \n",
      " 11  log_cite_count  768 non-null    float64       \n",
      " 12  author_id       768 non-null    int8          \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), int8(1), object(6)\n",
      "memory usage: 78.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('sc_cases_cleaned.pkl', compression='gzip')\n",
    "df = df.assign(author_id=(df['authorship']).astype('category').cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff560738",
   "metadata": {},
   "source": [
    "# GPT-2 and Language Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb6c226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T08:01:02.035133Z",
     "start_time": "2022-05-13T08:00:54.649806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load GPT2\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fcab8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T08:42:36.521369Z",
     "start_time": "2022-05-13T08:42:33.586033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating and sharing my own ideas and ideas for the future. I'm always looking for new ways to make my life better. I'm always looking for ways to make my life better.\n",
      "\n",
      "I'm always looking for ways to make my\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('I enjoy generating', return_tensors='pt')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a55ae9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T08:42:37.796560Z",
     "start_time": "2022-05-13T08:42:36.522425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating my own content, so I'm always looking for ways to improve it.\n",
      "\n",
      "If you have any questions or comments, feel free to leave them in the comments below.\n"
     ]
    }
   ],
   "source": [
    "# activate beam search and early_stopping\n",
    "\n",
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, # to avoid repetitions of the same word sequences\n",
    "    early_stopping=True\n",
    ")\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb4d056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T08:42:38.883258Z",
     "start_time": "2022-05-13T08:42:37.797505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating both cheats and side-splice hunts for items (e.g., armor) in dragons encounter lists! It's great to: 1) decide where to keep the item, 2) influence tree-based walkthrough options (\n"
     ]
    }
   ],
   "source": [
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123c370e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T08:42:59.843514Z",
     "start_time": "2022-05-13T08:42:58.617708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating animation. You get a glimpse into the mind of the animated character, but also this realm of imagination. Don't have a chance of unlocking animation that will pique your interest while you're young. Focus on the thought processes. Keep\n"
     ]
    }
   ],
   "source": [
    "# sample only from 92% most likely words\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n",
    "# arguably the best generation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ea5ee07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T19:03:26.843906Z",
     "start_time": "2022-05-12T19:03:25.884059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating and maintaining fair and just content both physically and digitally, but providing no vision and effort in an effort to control/loss our views,\" PCUSA VP of Media Relations Jason Varner told the site. \"Even where iOS also makes websites\n"
     ]
    }
   ],
   "source": [
    "# typical sampling: https://arxiv.org/pdf/2202.00666.pdf\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    typical=0.1, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6c864",
   "metadata": {},
   "source": [
    "**GPTNeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9117d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T17:55:13.576322Z",
     "start_time": "2022-05-12T17:55:06.369307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy generating images to use in desktop environment; I find myself frustrated every time I try to change file paths, but these are simply too quick and efficient to a certain extent.\n",
      "\n",
      "First of all, I would like to ask some questions about\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoForCausalLM\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "input_ids = tokenizer.encode('I enjoy generating', return_tensors='pt')\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448beb5",
   "metadata": {},
   "source": [
    "**Conditional Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbb58eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T17:55:27.027053Z",
     "start_time": "2022-05-12T17:55:25.834087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump: Jobs are everywhere, every American has some role in creating jobs. But if you haven't been involved in raising funds for progressive goals and economic reform, you’re not a human being at all, you’re a worker\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Donald Trump:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87837832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T17:55:36.862860Z",
     "start_time": "2022-05-12T17:55:35.668957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden: Standing in the White House. Photo: Margareta Porter/Getty Images\n",
      "\n",
      "And there is one thing that Barack Obama, the candidate of good intentions, and Christopher Dodd, the Federal Reserve Board chairman, are unappealing to\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Joe Biden:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10504a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T17:55:52.002737Z",
     "start_time": "2022-05-12T17:55:50.895068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justice Ruth Bader Ginsburg: Goldman Sachs has lost its own national cooperation with Britain’s corporate executive, Uli Bond, on reports that Goldman Sachs had been engaged in a co-optation of the Rhoads, a video game\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('Justice Ruth Bader Ginsburg:', return_tensors=\"pt\")\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65169faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
